{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Invaders own implementation\n",
    "\n",
    "## Intro \n",
    "This is my first try to play the Atari game of SpaceInvaders with the use of tensorflow. Allthough there is some code out there I want to understand it myself. Hence here my own implementation.\n",
    "\n",
    "## General\n",
    "- [Stackoverflow](\"https://stackoverflow.com/questions/42605769/openai-gym-atari-on-windows\") about running Atari on Windows\n",
    "\n",
    "\n",
    "## about OpenAI\n",
    "- [Doku](\"https://gym.openai.com/docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if it works\n",
    "for i_episode in range(10):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        observation\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"finisched\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
    "possible_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the preprocessing functions\n",
    "In this case we are receiving the fully coloered pictures. Even with the scores on top.\n",
    "\n",
    "\n",
    "__Observation:__ Here we receive the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape  (210, 160, 3)\n",
      "reward 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"observation shape \", observation.shape)\n",
    "plt.imshow(observation)\n",
    "print(\"reward\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessImage(observation):\n",
    "    img = rgb2gray(observation) \n",
    "    img = img[20:-12,4:-12] # crop image\n",
    "    img = img / 255 # normalize image\n",
    "    img = transform.rescale(img, 1/1.9)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after processing (94, 76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# stack 4 pictures \n",
    "# this is important so that the ai \n",
    "# is able to understand how the oponents move\n",
    "img = preProcessImage(observation)\n",
    "\n",
    "print(\"shape after processing\", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames  =  deque([np.zeros(img.shape, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # Preprocess frame\n",
    "    frame = preProcessImage(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros(img.shape, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "        \n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Build the stacked state (first dimension specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2) \n",
    "    \n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [94, 76, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n",
    "action_size = env.action_space.n # 8 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 50            # Total episodes for training\n",
    "max_steps = 50000              # Max possible steps in an episode\n",
    "batch_size = 64                # Batch size\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.9                    # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "stack_size = 4                 # Number of frames stacked\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Setup Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
    "            self.actions = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions\")\n",
    "            \n",
    "            \n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.inputs_,\n",
    "                                          filters = 32,\n",
    "                                          kernel_size = [8,8],\n",
    "                                          strides = [4,4],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv1\")\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            \n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1_out,\n",
    "                                          filters = 64,\n",
    "                                          kernel_size = [4,4],\n",
    "                                          strides = [2,2],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv2\")\n",
    "            \n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")\n",
    "            \n",
    "            \n",
    "            self.conv3 = tf.layers.conv2d(inputs = self.conv2_out,\n",
    "                                          filters = 64,\n",
    "                                          kernel_size = [3,3],\n",
    "                                          strides = [2,2],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv3\")\n",
    "            \n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            self.flatten = tf.contrib.layers.flatten(self.conv3_out)\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                     units = 512,\n",
    "                                     activation = tf.nn.elu,\n",
    "                                     kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                     name = \"fc1\")\n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc,\n",
    "                                        units = self.action_size,\n",
    "                                        activation = None)\n",
    "            \n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions))\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "DQNetwork = DQNetwork(state_size, action_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Experience Replay\n",
    "[Experience Replay](\"https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4cf2d728353a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-58be3a5256eb>\u001b[0m in \u001b[0;36mstack_frames\u001b[1;34m(stacked_frames, state, is_new_episode)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Append frame to deque, automatically removes the oldest frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mstacked_frames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Build the stacked state (first dimension specifies different frames)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "memory = Memory(max_size=memory_size)\n",
    "env.reset()\n",
    "for i in range(pretrain_length):\n",
    "    if i == 0:\n",
    "        state = env.reset()        \n",
    "        state, stacked_frames = stack_frames(stack_frames, state, True)\n",
    "        \n",
    "    choice = random.randint(1, len(possible_actions))-1\n",
    "    #action = possible_actions[choice]\n",
    "    next_state, reward, done, _ = env.step(choice)\n",
    "    \n",
    "    next_state, stacked_frames = stack_frames(stack_frames, next_state, False)\n",
    "    \n",
    "    \n",
    "    if done:\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up Tensorboard \n",
    "[Tutorial](\"https://www.youtube.com/embed/eBbEDRsCmv4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train your Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
