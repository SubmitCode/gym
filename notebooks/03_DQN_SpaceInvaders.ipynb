{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Invaders own implementation\n",
    "\n",
    "## Intro \n",
    "This is my first try to play the Atari game of SpaceInvaders with the use of tensorflow. Allthough there is some code out there I want to understand it myself. Hence here my own implementation.\n",
    "\n",
    "## General\n",
    "- [Stackoverflow](\"https://stackoverflow.com/questions/42605769/openai-gym-atari-on-windows\") about running Atari on Windows\n",
    "\n",
    "\n",
    "## about OpenAI\n",
    "- [Doku](\"https://gym.openai.com/docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if it works\n",
    "for i_episode in range(10):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        observation\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"finisched\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
    "possible_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the preprocessing functions\n",
    "In this case we are receiving the fully coloered pictures. Even with the scores on top.\n",
    "\n",
    "\n",
    "__Observation:__ Here we receive the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape  (210, 160, 3)\n",
      "reward 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"observation shape \", observation.shape)\n",
    "plt.imshow(observation)\n",
    "print(\"reward\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessImage(observation):\n",
    "    img = rgb2gray(observation) \n",
    "    img = img[20:-12,4:-12] # crop image\n",
    "    img = img / 255 # normalize image\n",
    "    img = transform.rescale(img, 1/1.9)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after processing (94, 76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# stack 4 pictures \n",
    "# this is important so that the ai \n",
    "# is able to understand how the oponents move\n",
    "img = preProcessImage(observation)\n",
    "\n",
    "print(\"shape after processing\", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames  =  deque([np.zeros(img.shape, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # Preprocess frame\n",
    "    frame = preProcessImage(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros(img.shape, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "        \n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Build the stacked state (first dimension specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2) \n",
    "    \n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [94, 76, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n",
    "action_size = env.action_space.n # 8 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 50            # Total episodes for training\n",
    "max_steps = 50000              # Max possible steps in an episode\n",
    "batch_size = 64                # Batch size\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.9                    # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "stack_size = 4                 # Number of frames stacked\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Setup Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
    "            self.actions = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions\")\n",
    "            \n",
    "            \n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.inputs_,\n",
    "                                          filters = 32,\n",
    "                                          kernel_size = [8,8],\n",
    "                                          strides = [4,4],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv1\")\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            \n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1_out,\n",
    "                                          filters = 64,\n",
    "                                          kernel_size = [4,4],\n",
    "                                          strides = [2,2],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv2\")\n",
    "            \n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")\n",
    "            \n",
    "            \n",
    "            self.conv3 = tf.layers.conv2d(inputs = self.conv2_out,\n",
    "                                          filters = 64,\n",
    "                                          kernel_size = [3,3],\n",
    "                                          strides = [2,2],\n",
    "                                          padding = \"VALID\",\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                          name = \"conv3\")\n",
    "            \n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            self.flatten = tf.contrib.layers.flatten(self.conv3_out)\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                     units = 512,\n",
    "                                     activation = tf.nn.elu,\n",
    "                                     kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                     name = \"fc1\")\n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc,\n",
    "                                        units = self.action_size,\n",
    "                                        activation = None)\n",
    "            \n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions))\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "DQNetwork = DQNetwork(state_size, action_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Experience Replay\n",
    "[Experience Replay](\"https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\wilhe\\Miniconda3\\envs\\gym3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f570f149efbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-58be3a5256eb>\u001b[0m in \u001b[0;36mstack_frames\u001b[1;34m(stacked_frames, state, is_new_episode)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Append frame to deque, automatically removes the oldest frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mstacked_frames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Build the stacked state (first dimension specifies different frames)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "memory = Memory(max_size=memory_size)\n",
    "for i in range(pretrain_length):\n",
    "    if i == 0:\n",
    "        state = env.reset()        \n",
    "        state, stacked_frames = stack_frames(stack_frames, state, True)\n",
    "        \n",
    "    choice = random.randint(1, len(possible_actions))-1\n",
    "    #action = possible_actions[choice]\n",
    "    next_state, reward, done, _ = env.step(choice)\n",
    "    \n",
    "    next_state, stacked_frames = stack_frames(stack_frames, next_state, False)\n",
    "    \n",
    "    \n",
    "    if done:\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up Tensorboard \n",
    "[Tutorial](\"https://www.youtube.com/embed/eBbEDRsCmv4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train your Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
